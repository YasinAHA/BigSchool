---
theme: default
---

# Lecci√≥n 13: Observability Strategy

## Testear Menos vs Observar M√°s

---

## Agenda

- El Dilema: Testing vs Observability
- Framework de Decisi√≥n (4 Preguntas)
- Matriz por Etapa del Proyecto
- Casos de Estudio Reales
- ROI de Observability

---

## ¬øQu√© es ROI?

**ROI (Return on Investment)**: Retorno sobre la inversi√≥n

**F√≥rmula**:

```
ROI = (Beneficio - Costo) / Costo
```

**Ejemplo pr√°ctico**:

```
Escribir tests: 150 minutos (costo)
Feature adoption: 5% usuarios (beneficio bajo)
ROI: NEGATIVO (-26h desperdiciadas)

Setup observability: 10 minutos (costo)
Descubrir adoption temprano: 5% (beneficio: evitar 140 min)
ROI: POSITIVO (+140 min ahorrados)
```

**En esta lecci√≥n**: Medimos ROI de testing vs observability para

tomar decisiones inteligentes

---

## La Pregunta Central

> ¬øCu√°ndo debemos **testear exhaustivamente** vs **observar en producci√≥n**?

**Respuesta**: Depende del **ROI** y la **fase del proyecto**

**Idea Clave**:

- Tests predicen problemas conocidos
- Observability descubre problemas desconocidos

---

## Framework: 4 Preguntas Clave

**1. ¬øConoces el comportamiento esperado?**

```
‚úÖ TESTEAR: Comportamiento definido
- C√°lculos financieros
- Validaciones de negocio
- APIs con contratos

üîç OBSERVAR: Comportamiento incierto
- ¬øQu√© features usan usuarios?
- ¬øD√≥nde abandonan el flujo?
- ¬øC√≥mo navegan realmente?
```

---

## Framework (cont.)

**2. ¬øCu√°l es el costo de fallar?**

```
‚úÖ TESTEAR: Costo alto
- Transacciones financieras
- Sistemas cr√≠ticos de seguridad
- L√≥gica core del negocio

üîç OBSERVAR: Costo bajo-medio
- Mejoras de UX/UI
- Features experimentales
- Optimizaciones de performance
```

---

## Framework (cont.)

**3. ¬øQu√© tan estable es el requisito?**

```
‚úÖ TESTEAR: Requisitos estables
- Reglas de negocio consolidadas
- APIs p√∫blicas maduras
- Sistemas legacy establecidos

üîç OBSERVAR: Requisitos cambian
- Features nuevas en exploraci√≥n
- Experimentos A/B
- Comportamiento incierto
```

---

## Framework (cont.)

**4. ¬øPuedes simular el escenario real?**

```
‚úÖ TESTEAR: Simulaci√≥n efectiva
- L√≥gica pura (input ‚Üí output)
- Casos de borde conocidos
- Integraciones con mocks

üîç OBSERVAR: Simulaci√≥n limitada
- Comportamiento de usuario real
- Performance con datos producci√≥n
- Interacciones complejas del sistema
```

---

## Matriz por Etapa del Proyecto

**üöÄ Etapa MVP**:

```
Prioridad: OBSERVAR > TESTEAR

60% Observability
- Seguimiento de errores
- Recorridos de usuario
- M√©tricas de adopci√≥n

40% Testing
- Tests de humo
- Happy path (camino feliz)
- Casos cr√≠ticos

¬øPor qu√©? No sabemos qu√© funciona a√∫n
```

---

## Matriz (cont.)

**üìà Etapa de Crecimiento**:

```
Prioridad: BALANCEADO

50% Observability
- Performance
- Embudos de conversi√≥n
- Pruebas A/B

50% Testing
- Pruebas de regresi√≥n
- Tests de integraci√≥n

¬øPor qu√©? Optimizar manteniendo estabilidad
```

---

## Matriz (cont.)

**üèóÔ∏è Etapa de Escala**:

```
Prioridad: TESTEAR > OBSERVAR

70% Testing
- Coverage exhaustivo
- Pruebas de contrato
- Pruebas de performance

30% Observability
- Monitoreo
- Alertas
- Inteligencia de negocio

¬øPor qu√©? Estabilidad es cr√≠tica
```

---

## Caso 1: Feature de Descuentos

**‚ùå Mal enfoque - Solo Testing**:

```typescript {*}{maxHeight:'300px'}
// 50 tests cubriendo todos edge cases
it('should apply 15% discount for $100+ orders')
it('should apply 10% bulk discount for 5+ items')
// ... 47 tests m√°s

Resultado:
- 40 horas escribiendo tests
- 2 bugs encontrados
- No sabemos si usuarios usan descuentos
```

---

## Caso 1 (cont.)

**‚úÖ Buen enfoque - Testing + Observability**:

```typescript {*}{maxHeight:'300px'}
// 5 tests para casos cr√≠ticos
it('should calculate discounts correctly')

// Observabilidad para uso real
captureBusinessMetric('discount.applied', {
  discount_type: 'bulk|order|seasonal',
  user_segment: 'new|returning|premium'
})

Resultado:
- 8 horas implementando
- Descubrimos: nadie usa descuentos estacionales
- Eliminamos feature ‚Üí ahorro 20 horas
```

---

## Caso 2: Performance de Checkout

**‚ùå Mal enfoque**:

```typescript {*}{maxHeight:'200px'}
// Tests con datos sint√©ticos
it('checkout should complete in under 2 seconds')

Resultado:
- Tests pasan en desarrollo
- No detecta problemas reales
```

**‚úÖ Buen enfoque**:

```typescript {*}{maxHeight:'200px'}
// Timing real
const endTiming = startBusinessTiming('checkout_process')
// ... l√≥gica
endTiming({ user_type, cart_size, payment_method })

Resultado:
- 80% usuarios abandonan en step 3
- Optimizamos UX ‚Üí +15% conversion
```

---

## Estrategias Pr√°cticas

**Para Features Nuevas (MVP)**:

```typescript {*}{maxHeight:'300px'}
// 1. Empezar con Observability
captureUserJourney('feature_used', {
  feature: 'new_calculator'
})

// 2. Testear solo Happy Path
it('should calculate correctly for common case')

// 3. Observar uso real
if (adoption < 5%) {
  // Remover feature en lugar de agregar tests
}
```

---

## Se√±ales de Alerta

**üö© Exceso de Testing**:

- M√°s tiempo tests que features
- Tests que nunca fallan
- 100% coverage en features experimentales
- Tests de implementaci√≥n, no comportamiento

**Cura**: Agregar observability, remover tests redundantes

**üö© Falta de Observability**:

- No sabes c√≥mo usan tu producto
- Bugs reportados por usuarios, no tu sistema
- Problemas de performance descubiertos accidentalmente

**Cura**: Agregar m√©tricas de negocio, seguimiento de errores

---

## Ejercicio: An√°lisis de ROI

**Feature "Favoritos" en e-commerce**:

**Opci√≥n A: Testing Primero**

- Esfuerzo: 20h tests + 8h feature = 28h
- Resultado: Perfectamente testeada, solo 2% uso
- ROI: Negativo (-26h desperdiciadas)

**Opci√≥n B: Observability Primero**

- Esfuerzo: 2h observability + 8h feature = 10h
- Resultado: Descubres que prefieren "Comprar despu√©s"
- ROI: Positivo (+18h ahorradas + feature √∫til)

---

## Ejercicio 1: Testing vs Observability con Framework

**Prompt**:

```bash {*}{maxHeight:'300px'}
Act√∫a como un arquitecto de software aplicando Framework 4 Preguntas para decidir estrategia.

CONTEXTO: Pregunta central: "¬øCu√°ndo testear exhaustivamente vs observar en
producci√≥n?". Respuesta: Depende de ROI y fase del proyecto. Tests predicen
problemas conocidos (comportamiento definido). Observability descubre problemas
desconocidos (comportamiento incierto). Framework 4 Preguntas: 1) ¬øConoces
comportamiento esperado? (S√ç ‚Üí testear), 2) ¬øCosto de fallar? (Alto ‚Üí testear),
3) ¬øRequisito estable? (S√ç ‚Üí testear), 4) ¬øSimulable en tests? (S√ç ‚Üí testear).
3/4 respuestas S√ç ‚Üí testear, 3/4 NO ‚Üí observar. Lo mejor de ambos: combinar testing
+ observability para cobertura completa.

TAREA: Analiza funci√≥n applyPromoCode usando Framework 4 Preguntas y decide estrategia.

FUNCI√ìN A ANALIZAR:
- Nombre: applyPromoCode(code: string, cartTotal: number): number
- Prop√≥sito: Aplica c√≥digos promocionales (% descuento)
- L√≥gica: Valida c√≥digo ‚Üí calcula descuento ‚Üí retorna monto descontado
- Uso: E-commerce checkout flow

FRAMEWORK 4 PREGUNTAS (Responder S√ç/NO + raz√≥n):

Pregunta 1: ¬øConoces comportamiento esperado?
- Analizar: ¬øC√≥digos est√°n definidos en DB? ¬øReglas claras?
- Respuesta: [S√ç/NO] - [raz√≥n]

Pregunta 2: ¬øCosto de fallar es alto?
- Analizar: ¬øAfecta dinero? ¬øP√©rdida de revenue? ¬øImpacto cr√≠tico?
- Respuesta: [S√ç/NO] - [raz√≥n]

Pregunta 3: ¬øRequisito estable?
- Analizar: ¬øReglas de descuento cambian frecuentemente?
- Respuesta: [S√ç/NO] - [raz√≥n]

Pregunta 4: ¬øSimulable en tests?
- Analizar: ¬øInputs/outputs conocidos? ¬øCasos predecibles?
- Respuesta: [S√ç/NO] - [raz√≥n]

DECISI√ìN REQUERIDA:
- Contar S√ç: [X/4]
- Estrategia: [TESTEAR/OBSERVAR/H√çBRIDA]
- Justificaci√≥n: [2-3 oraciones basadas en respuestas]

SI TESTEAR:
- Especificar tests requeridos (unitarios, edge cases)

SI OBSERVAR:
- Especificar m√©tricas a observar

SI H√çBRIDA:
- Testing: [qu√© testear]
- Observability: [qu√© observar]

VALIDACI√ìN: Decisi√≥n debe ser TESTEAR (funci√≥n cr√≠tica de dinero)
```

**Aprende**: Framework sistem√°tico transforma decisiones

subjetivas en objetivas

---

## Ejercicio 2: Calcular ROI Testing vs Observability

**Prompt**:

```bash {*}{maxHeight:'300px'}
Act√∫a como un product engineer calculando ROI para decidir entre testing vs observability.

CONTEXTO: ROI (Return on Investment - retorno sobre inversi√≥n) mide si inversi√≥n
de tiempo vale la pena. F√≥rmula: ROI = (Beneficio - Costo) / Costo. Testing
Primero: alto costo inicial (150 min escribir tests), beneficio solo si feature
se usa. Observability Primero: bajo costo inicial (10 min setup), descubre
adopci√≥n real antes de invertir en tests. Features experimentales: adopci√≥n
desconocida (puede ser 2% o 80%). Regla pragm√°tica: adopci√≥n > 50% ‚Üí testear
exhaustivamente, adopci√≥n < 20% ‚Üí considerar remover/mejorar.

TAREA: Calcula ROI de ambas opciones para feature experimental con 5% adopci√≥n.

ESCENARIO:
- Feature: Nueva funcionalidad "Quick Reorder" (reordenar r√°pido)
- Adopci√≥n esperada: DESCONOCIDA (puede ser 2% o 80%)
- Adopci√≥n real: 5% (descubierto despu√©s)

OPCI√ìN A - TESTING PRIMERO:
- Esfuerzo: 5 edge cases √ó 30 min/test = 150 min
- Tests escritos: 5 tests comprehensivos
- Feature lanzada con tests completos
- Adopci√≥n descubierta: 5% de usuarios

OPCI√ìN B - OBSERVABILITY PRIMERO:
- Esfuerzo: Setup Sentry + tracking = 10 min
- Feature lanzada con observability
- Adopci√≥n descubierta: 5% de usuarios
- Decisi√≥n post-observability: ¬øVale la pena invertir 150 min en tests?

C√ÅLCULO ROI REQUERIDO:

Opci√≥n A (Testing Primero):
- Costo: [tiempo en min]
- Beneficio: [valor seg√∫n adopci√≥n real 5%]
- ROI: [positivo/negativo + cantidad]
- Conclusi√≥n: [¬øvali√≥ la pena?]

Opci√≥n B (Observability Primero):
- Costo: [tiempo en min]
- Beneficio: [tiempo ahorrado al descubrir baja adopci√≥n temprano]
- ROI: [positivo/negativo + cantidad]
- Conclusi√≥n: [¬øvali√≥ la pena?]

AN√ÅLISIS COMPARATIVO:
- Diferencia ROI: [A vs B]
- Decisi√≥n √≥ptima: [cu√°l opci√≥n]
- Regla extra√≠da: [cu√°ndo usar cada enfoque]

VALIDACI√ìN: Opci√≥n B debe tener ROI superior (+140 min ahorrados)
```

**Aprende**: Observability primero en features inciertas

maximiza ROI minimizando desperdicio

---

## Puntos Clave

1. **No hay regla √∫nica**: Balance depende del contexto
2. **ROI sobre Coverage**: Impacto de negocio > m√©tricas vanidosas
3. **Evoluciona**: MVP ‚Üí Crecimiento ‚Üí Escala requieren enfoque diferente
4. **Observa primero**: En features nuevas, observar > testear
5. **Testea lo cr√≠tico**: En sistemas maduros, testear > observar
6. **M√©tricas de negocio**: Mide lo que importa al negocio
7. **Datos de usuarios reales**: Datos de producci√≥n > tests sint√©ticos
